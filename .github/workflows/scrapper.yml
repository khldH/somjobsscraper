name: run_scrapper

on:
  workflow_dispatch:
  schedule:
  - cron:  "0 */2 * * *"

jobs:
  build:
    runs-on: ubuntu-latest
    env:
        AWS_ACCESS_KEY_ID: ${{secrets.AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{secrets.AWS_SECRET_ACCESS_KEY }}
        DYNAMODB_PIPELINE_TABLE_NAME: ${{secrets.DYNAMODB_PIPELINE_TABLE_NAME }}

    steps:
      - name: Checkout repository content
        uses: actions/checkout@v2 # Checkout the repository content to github runner
        
      - name: Run Splash
        run:
         docker run --rm -d -p 8050:8050 --network host scrapinghub/splash

      - name: Setup Python Version
        uses: actions/setup-python@v2
        with:
          python-version: 3.9 # Install the python version needed

      - name: Install Python dependencies
        uses: py-actions/py-dependency-install@v2
        with:
          path: "requirements.txt"
      
      
      - name: Execute Python script # Run the app.py
        run: |
          SPLASH_URL=http://127.0.0.1:8050
          python main.py
